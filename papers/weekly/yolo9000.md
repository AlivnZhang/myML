## YOLO9000: Better, Faster, Stronger

https://arxiv.org/abs/1612.08242




### 要点

1. Better(需要考虑到accuracy和realtime)
    * BN: 引入BN可以提高mAP 2%
    * hi-res classifier: 4% mAP
    * Conv with Anchor Boxes: object proposal的数量从98增加到数千个，mAP只有些微降低，但是recall提高
    * Dimension Clusters: 使用k-means clustering来确定IOC的prior，而不是人工来确定这些prior
    * direct location prediction: 解决model不稳定的问题
    * fine-grained features: passthrough layer来使用更小的resolution
    * multi-scale training: 训练中几个epoch调整输入图片的尺寸，这样训练出的Model可以在low-res/high-res的输入中自动平衡，例如可以平衡accuracy和speed
2. Faster
    * 很多detection的model都是基于VGG16的feature extractor，但是这个model需要30.69 billion浮点计算（只做一次224x224的图片处理）， Yolov2使用一个基于GoogleNet的简化的model，只需要8.52 billion. 相比于VGG16 accuracy只从90%减少到88%
    * 使用Darknet-19来作为classification model, 需要5.58 billion操作达到72.9%的accuracy
3. Stronger: 使用WordNet来build一个tree达到更精确的预测（root-leaf可以找到更specific的class）

    
![Yolo](/images/yolov2.png)

YOLO vs. YOLOv2


### 个人点评

1.自己的第一个线上部署的video analysis就是参考的这哥们的代码，而过去的几年，这哥们也是不断在改进他的算法和结构
2. OT：他的简历也是很萌，a pony's story, https://pjreddie.com/resume/
3. 从作者做出的改善来看，都是一些经验的体现，事实上与流行的end-to-end，或者说减少human engineering相悖。当然让机器来自己figure out的end-to-end还是引入人类的feature engineering(prior)哪个会更加有效目前也是没有定论的。当然，个人觉得在一些critical场景（例如这种realtime的场景），人类的prior的介入是必要的，这样可以更高效性。当然end-to-end适应的场景更广，也更加低门槛一些。
4. Object Detection这个领域一直就是2个路径，一个是rbg的end-to-end的RCNN（以及改进的fast/faster等）, 另一个就是此哥们的YOLO系列（更多是引入一些feature engineering的prior），从目前来看，实时性来看还是这个哥们的YOLO更好一些。(end to end的approach通常都有太多的冗余的参数，导致train/evaluation都会很慢）


### Resources

1. https://pjreddie.com/darknet/yolo/
