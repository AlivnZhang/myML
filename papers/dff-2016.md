##  Deep Feature Flow for Video Recognition

https://arxiv.org/pdf/1611.07715.pdf

### 要点

1. 使用key frame+feature flow解决逐帧处理的计算要求并不太损失精确度
2. 算法非常简单，具体见下面的流程图
3. {Ik, Ii}也就是对Ik帧通过CNN获取feature map，然后通过feature flow来获取Ii的feature map，这里0<=i-k<=9, 作者指出i==k是算法就退化为逐帧处理的方法
4. 一个关键问题是如何确定这里的l=i-k，也就是key frame duration，以及如何选择key frame是关键的点，而作者在文中只是说到是beyond the scope of this work

![alg](/images/dff.mmd.png)


### 个人点评

1. 之前我在处理video recognition时主要是通过跳过n帧来减小计算，但是也会出现错误跳过的情况
2. 事实上，我们都知道逐帧处理的低效，因为没有很好地使用相邻帧之间的相似属性，但是我们又不能直接跳过（就像我上面使用的方法，直接跳过N帧），因为这样会导致可能的对象丢失（帧之间出现了大的变化），但是如何使用这样的相邻帧相似性的属性是个问题，作者提出了自己的方法
3. 我在想如果可以计算不同图像的相似性（特别是特定object of interest下的），利用这个量化的值来应用到下一帧的对象检测上，是否可以取得较好的结果？
4. 本质问题是：如何使用某种方法来检测某一帧的对象，这种方法要性能优于直接使用CNN并且不能损失太多精确性
5. 作者提到的key frame和key frame length的确定是个极其关键的部分，而作者并没有给出研究，这也是个很好的切入点


### Resources

1. source code(official in MXNet): https://github.com/msracver/Deep-Feature-Flow
